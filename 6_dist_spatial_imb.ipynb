{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.compute as pc\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "PARQUET_CLEAN   = \"ldms_set1.parquet\"\n",
    "JOB_METRICS_OUT = \"job_metrics.parquet\"\n",
    "UTIL_COLUMN     = \"nersc_ldms_dcgm_gpu_utilization\"\n",
    "BATCH_SIZE      = 500_000\n",
    "ROW_GROUP_SIZE  = 500_000\n",
    "\n",
    "stats = defaultdict(lambda: {\"total_ts\": 0, \"sum_util\": 0.0})\n",
    "\n",
    "dataset = ds.dataset(PARQUET_CLEAN, format=\"parquet\")\n",
    "scanner = dataset.scanner(\n",
    "    columns=[\"JobID\", \"hostname\", \"gpu_id\", UTIL_COLUMN],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_threads=True\n",
    ")\n",
    "\n",
    "for rb in scanner.to_batches():\n",
    "    jid  = pc.cast(rb[\"JobID\"], pa.string()).to_pylist()\n",
    "    host = rb[\"hostname\"].to_pylist()\n",
    "    gpu  = pc.cast(rb[\"gpu_id\"], pa.int64()).to_numpy()\n",
    "    util = pc.cast(rb[UTIL_COLUMN], pa.float64()).to_numpy(zero_copy_only=False)\n",
    "\n",
    "    for j, h, g, u in zip(jid, host, gpu, util):\n",
    "        if j is None or np.isnan(u):\n",
    "            continue\n",
    "        key = (str(j), h, int(g))\n",
    "        d = stats[key]\n",
    "        d[\"total_ts\"] += 1\n",
    "        d[\"sum_util\"] += float(u)\n",
    "\n",
    "per_gpu = pd.DataFrame.from_records(\n",
    "    [(j, h, g, v[\"total_ts\"], v[\"sum_util\"]) for (j, h, g), v in stats.items()],\n",
    "    columns=[\"JobID\", \"hostname\", \"gpu_id\", \"total_timestamps\", \"total_utilization\"]\n",
    ")\n",
    "del stats\n",
    "\n",
    "per_gpu = per_gpu[per_gpu[\"total_timestamps\"] > 0].copy()\n",
    "per_gpu[\"gpu_mean\"] = per_gpu[\"total_utilization\"] / per_gpu[\"total_timestamps\"]\n",
    "\n",
    "job_df = (\n",
    "    per_gpu.groupby(\"JobID\", as_index=False)\n",
    "           .agg(mean_utilization=(\"gpu_mean\", \"mean\"))\n",
    ")\n",
    "\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(job_df, preserve_index=False),\n",
    "    JOB_METRICS_OUT,\n",
    "    compression=\"snappy\",\n",
    "    row_group_size=ROW_GROUP_SIZE,\n",
    ")\n",
    "job_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeef52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.compute as pc\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "SET1   = \"ldms_set1.parquet\"\n",
    "METRIC = \"nersc_ldms_dcgm_gpu_utilization\"\n",
    "\n",
    "SAMPLE_SEC = 10\n",
    "WINDOW_SEC = 60\n",
    "assert WINDOW_SEC % SAMPLE_SEC == 0\n",
    "TICKS_PER_WINDOW = WINDOW_SEC // SAMPLE_SEC\n",
    "\n",
    "SNS = SAMPLE_SEC * 1_000_000_000\n",
    "BATCH_SIZE = 500_000\n",
    "\n",
    "OUT_DIR_WIN_S1 = Path(\"si_windows_set1_ldms_parts\")\n",
    "OUT_DIR_JOB_S1 = Path(\"si_jobs_set1_ldms_parts\")\n",
    "OUT_DIR_WIN_S1.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR_JOB_S1.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "@dataclass\n",
    "class JobAnchor:\n",
    "    ts0: int\n",
    "    g_ldms: int\n",
    "\n",
    "def build_job_anchors(parquet_path: str) -> dict:\n",
    "    ds_in = ds.dataset(parquet_path, format=\"parquet\")\n",
    "    scanner = ds_in.scanner(\n",
    "        columns=[\"JobID\", \"hostname\", \"gpu_id\", \"ts_ns\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        use_threads=True\n",
    "    )\n",
    "\n",
    "    ts0_map = {}\n",
    "    gpu_sets = defaultdict(set)\n",
    "\n",
    "    for rb in scanner.to_batches():\n",
    "        jid  = pc.cast(rb[\"JobID\"],  pa.string()).to_pylist()\n",
    "        host = rb[\"hostname\"].to_pylist()\n",
    "        gid  = pc.cast(rb[\"gpu_id\"], pa.int64()).to_numpy()\n",
    "        ts   = pc.cast(rb[\"ts_ns\"],  pa.int64()).to_numpy()\n",
    "\n",
    "        for j, h, g, t in zip(jid, host, gid, ts):\n",
    "            if j is None:\n",
    "                continue\n",
    "            prev = ts0_map.get(j)\n",
    "            if prev is None or t < prev:\n",
    "                ts0_map[j] = int(t)\n",
    "            gpu_sets[j].add((h, int(g)))\n",
    "\n",
    "    anchors = {}\n",
    "    for j, t0 in ts0_map.items():\n",
    "        gobs = len(gpu_sets[j])\n",
    "        # drop single-GPU jobs because spatial imbalance is for multi-GPU jobs\n",
    "        if gobs > 1:  \n",
    "            anchors[j] = JobAnchor(ts0=int(t0), g_ldms=gobs)\n",
    "\n",
    "    return anchors\n",
    "\n",
    "def compute_gpuutil_si(parquet_path: str, anchors: dict) -> None:\n",
    "    ds_in = ds.dataset(parquet_path, format=\"parquet\")\n",
    "    cols = [\"JobID\", \"hostname\", \"gpu_id\", \"ts_ns\", METRIC]\n",
    "    scanner = ds_in.scanner(columns=cols, batch_size=BATCH_SIZE, use_threads=True)\n",
    "\n",
    "    tc_per_gpu = defaultdict(float)\n",
    "    seen_jobs = set()\n",
    "\n",
    "    for rb in scanner.to_batches():\n",
    "        jid  = pc.cast(rb[\"JobID\"],  pa.string()).to_pylist()\n",
    "        host = rb[\"hostname\"].to_pylist()\n",
    "        gid  = pc.cast(rb[\"gpu_id\"], pa.int64()).to_numpy()\n",
    "        ts   = pc.cast(rb[\"ts_ns\"],  pa.int64()).to_numpy()\n",
    "        val  = pc.cast(rb[METRIC],   pa.float64()).to_numpy(zero_copy_only=False)\n",
    "\n",
    "        for j, h, g, t, v in zip(jid, host, gid, ts, val):\n",
    "            if j is None or np.isnan(v):\n",
    "                continue\n",
    "            a = anchors.get(j)\n",
    "            if a is None:\n",
    "                continue\n",
    "\n",
    "            dt = t - a.ts0\n",
    "            if dt < 0:\n",
    "                continue\n",
    "\n",
    "            k = int((dt + (SNS // 2)) // SNS)\n",
    "            widx = k // TICKS_PER_WINDOW\n",
    "\n",
    "            tc_per_gpu[(j, widx, (h, int(g)))] += float(v)\n",
    "            seen_jobs.add(j)\n",
    "\n",
    "    if not tc_per_gpu:\n",
    "        print(\"no present windows.\")\n",
    "        return\n",
    "\n",
    "    sum_tc_by_win = defaultdict(float)\n",
    "    max_tc_by_win = defaultdict(float)\n",
    "\n",
    "    for (j, widx, _gpu_key), tc in tc_per_gpu.items():\n",
    "        key = (j, widx)\n",
    "        sum_tc_by_win[key] += tc\n",
    "        if tc > max_tc_by_win[key]:\n",
    "            max_tc_by_win[key] = tc\n",
    "\n",
    "    win_rows = []\n",
    "    for (j, widx), sum_tc in sum_tc_by_win.items():\n",
    "        max_tc = max_tc_by_win[(j, widx)]\n",
    "        g_ldms = anchors[j].g_ldms\n",
    "\n",
    "        if max_tc <= 0 or g_ldms <= 0:\n",
    "            si_w = 0.0\n",
    "        else:\n",
    "            si_w = 1.0 - (sum_tc / (max_tc * g_ldms))\n",
    "            if si_w < 0.0: si_w = 0.0\n",
    "            if si_w > 1.0: si_w = 1.0\n",
    "\n",
    "        win_rows.append((j, METRIC, widx, float(sum_tc), float(max_tc), int(g_ldms), float(si_w)))\n",
    "\n",
    "    win_df = pd.DataFrame(\n",
    "        win_rows,\n",
    "        columns=[\"JobID\", \"metric\", \"window_idx\", \"sum_TC\", \"max_TC\", \"g_ldms\", \"SI_jw\"]\n",
    "    )\n",
    "    out_win_file = OUT_DIR_WIN_S1 / f\"{METRIC}.parquet\"\n",
    "    pq.write_table(pa.Table.from_pandas(win_df, preserve_index=False), out_win_file, compression=\"snappy\")\n",
    "\n",
    "    w_present_by_job = defaultdict(int)\n",
    "    si_sum_by_job = defaultdict(float)\n",
    "    active_any_by_job = defaultdict(bool)\n",
    "\n",
    "    for _, r in win_df.iterrows():\n",
    "        j = r[\"JobID\"]\n",
    "        w_present_by_job[j] += 1\n",
    "        si_sum_by_job[j] += r[\"SI_jw\"]\n",
    "        if r[\"max_TC\"] > 0:\n",
    "            active_any_by_job[j] = True\n",
    "\n",
    "    job_rows = []\n",
    "    for j in seen_jobs:\n",
    "        w_present = w_present_by_job.get(j, 0)\n",
    "        if w_present == 0:\n",
    "            continue\n",
    "        if not active_any_by_job.get(j, False):\n",
    "            continue\n",
    "        si_mean = si_sum_by_job[j] / float(w_present)\n",
    "        job_rows.append((j, METRIC, int(anchors[j].g_ldms), int(w_present), float(si_mean)))\n",
    "\n",
    "    if not job_rows:\n",
    "        print(\"no jobs passed the filters.\")\n",
    "        return\n",
    "\n",
    "    job_df = pd.DataFrame(job_rows, columns=[\"JobID\", \"metric\", \"g_ldms\", \"w_present\", \"SI_mean\"])\n",
    "    out_job_file = OUT_DIR_JOB_S1 / f\"{METRIC}.parquet\"\n",
    "    pq.write_table(pa.Table.from_pandas(job_df, preserve_index=False), out_job_file, compression=\"snappy\")\n",
    "\n",
    "anchors = build_job_anchors(SET1)\n",
    "if not anchors:\n",
    "    raise RuntimeError(\"No multi-GPU jobs found.\")\n",
    "compute_gpuutil_si(SET1, anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from setup_plot import setup_local, get_colors, get_markers\n",
    "\n",
    "JOB_METRICS = \"job_metrics.parquet\"\n",
    "SI_PATH = \"si_jobs_set1_ldms_parts/nersc_ldms_dcgm_gpu_utilization.parquet\"\n",
    "\n",
    "def load_si(si_path):\n",
    "    si = pd.read_parquet(si_path)\n",
    "    si = si[[\"JobID\", \"SI_mean\"]].rename(columns={\"SI_mean\": \"spatial_imbalance_gpu_utilization\"})\n",
    "    si[\"JobID\"] = si[\"JobID\"].astype(str)\n",
    "    return si\n",
    "\n",
    "def load_job_metrics(job_metrics_path):\n",
    "    jm = pd.read_parquet(job_metrics_path, columns=[\"JobID\", \"mean_utilization\"]).copy()\n",
    "    jm[\"JobID\"] = jm[\"JobID\"].astype(str)\n",
    "    return jm\n",
    "\n",
    "def compute_hist_cdf_low(series):\n",
    "    hist_values, bin_edges = np.histogram(\n",
    "        series.dropna().clip(0, 1),\n",
    "        bins=20, range=(0, 1), density=False\n",
    "    )\n",
    "    cumulative_hist = np.cumsum(hist_values)\n",
    "    cdf = cumulative_hist / cumulative_hist[-1] * 100.0 if cumulative_hist[-1] > 0 else cumulative_hist.astype(float)\n",
    "    return hist_values, bin_edges, cdf\n",
    "\n",
    "def compute_hist_cdf_mid_high(series):\n",
    "    hist_values, bin_edges = np.histogram(series.clip(0, 1), bins=20, density=False)\n",
    "    cumulative_hist = np.cumsum(hist_values)\n",
    "    cdf = cumulative_hist / cumulative_hist[-1] * 100 if cumulative_hist[-1] > 0 else cumulative_hist.astype(float)\n",
    "    return hist_values, bin_edges, cdf\n",
    "\n",
    "def plot_band_0_30(df, bin_edges, cdf):\n",
    "    setup_local()\n",
    "    colors = get_colors()\n",
    "    markers = get_markers()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(df[\"spatial_imbalance_gpu_utilization\"], bins=20, range=(0, 1),\n",
    "             edgecolor=\"black\", alpha=0.7, color=colors[2])\n",
    "    ax1.set_xlabel(\"Spatial imb. (of GPU_UTIL)\\n(mean of GPU_UTIL: 0%–30%)\", fontsize=21)\n",
    "    ax1.set_ylabel(\"Number of jobs\", fontsize=21)\n",
    "    ax1.set_xlim(0)\n",
    "    ax1.set_ylim(0, 10000)\n",
    "    ax1.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax1.set_yticks([0, 2000, 4000, 6000, 8000, 10000])\n",
    "    ax1.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=20)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n",
    "    ax2.plot(bin_centers, cdf, color=colors[0], marker=markers[2],\n",
    "             label=\"CDF (number of Jobs)\", linewidth=2, clip_on=False)\n",
    "    ax2.set_ylabel(\"Cumulative percentage (%)\", fontsize=21)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "    ax2.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.legend(loc=\"best\", fontsize=18, framealpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return cdf\n",
    "\n",
    "def plot_band_31_69(df, bin_edges, cdf):\n",
    "    setup_local()\n",
    "    colors, markers = get_colors(), get_markers()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(df[\"spatial_imbalance_gpu_utilization\"], bins=20, range=(0, 1),\n",
    "             edgecolor=\"black\", alpha=0.7, color=colors[2])\n",
    "    ax1.set_xlabel(f\"GPU_UTIL Temporal Imbalance\")\n",
    "    ax1.set_ylabel(\"Number of jobs\", fontsize=21)\n",
    "    ax1.set_xlim(0)\n",
    "    ax1.set_xlabel(\"Spatial imb. (of GPU_UTIL)\\n(mean of GPU_UTIL: 31%–69%)\", fontsize=21)\n",
    "    ax1.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax1.set_yticks([0, 2000, 4000, 6000, 8000, 10000])\n",
    "    ax1.set_ylim(0, 10000)\n",
    "    ax1.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot((bin_edges[:-1] + bin_edges[1:]) / 2, cdf, color=colors[0], marker=markers[2],\n",
    "             label=\"CDF (number of jobs)\", linewidth=2, clip_on=False)\n",
    "    ax2.set_ylabel(\"Cumulative percentage (%)\", fontsize=21)\n",
    "    ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    ax2.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax2.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "    ax2.set_ylim(0, 100)\n",
    "\n",
    "    plt.legend(loc=\"best\", fontsize=18, framealpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return cdf\n",
    "\n",
    "def plot_band_70_100(df, bin_edges, cdf):\n",
    "    setup_local()\n",
    "    colors, markers = get_colors(), get_markers()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(df[\"spatial_imbalance_gpu_utilization\"], bins=20, range=(0, 1),\n",
    "             edgecolor=\"black\", alpha=0.7, color=colors[2])\n",
    "    ax1.set_xlabel(f\"GPU_UTIL Temporal Imbalance\")\n",
    "    ax1.set_ylabel(\"Number of jobs\")\n",
    "    ax1.set_xlim(0)\n",
    "    ax1.set_xlabel(\"Spatial imb. (of GPU_UTIL)\\n(mean of GPU_UTIL: 70%–100%)\", fontsize=21)\n",
    "    ax1.set_yticks([0, 2000, 4000, 6000, 8000, 10000])\n",
    "    ax1.set_ylim(0, 10000)\n",
    "    ax1.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax1.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot((bin_edges[:-1] + bin_edges[1:]) / 2, cdf, color=colors[0], marker=markers[2],\n",
    "             label=\"CDF (Number of Jobs)\", linewidth=2, clip_on=False)\n",
    "    ax2.set_ylabel(\"Cumulative percentage (%)\", fontsize=21)\n",
    "    ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    ax2.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax2.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "    ax2.set_ylim(0, 100)\n",
    "\n",
    "    plt.legend(loc=\"center right\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return cdf\n",
    "\n",
    "si = load_si(SI_PATH)\n",
    "jm = load_job_metrics(JOB_METRICS)\n",
    "gputil_spatial = si.merge(jm, on=\"JobID\", how=\"inner\")\n",
    "\n",
    "# 0–30\n",
    "gputil_spatial_30 = gputil_spatial[(gputil_spatial[\"mean_utilization\"] >= 0) &\n",
    "                                   (gputil_spatial[\"mean_utilization\"] <= 30)].copy()\n",
    "_, bin_edges_30, cdf_30 = compute_hist_cdf_low(gputil_spatial_30[\"spatial_imbalance_gpu_utilization\"])\n",
    "cdf_0_30 = plot_band_0_30(gputil_spatial_30, bin_edges_30, cdf_30)\n",
    "\n",
    "# 31–69\n",
    "gputil_spatial_30_70 = gputil_spatial.query(\"30 < mean_utilization < 70\").copy()\n",
    "_, bin_edges_30_70, cdf_30_70 = compute_hist_cdf_mid_high(gputil_spatial_30_70[\"spatial_imbalance_gpu_utilization\"])\n",
    "cdf_31_69 = plot_band_31_69(gputil_spatial_30_70, bin_edges_30_70, cdf_30_70)\n",
    "\n",
    "# 70–100\n",
    "gputil_spatial_70 = gputil_spatial.query(\"70 <= mean_utilization <= 100\").copy()\n",
    "_, bin_edges_70, cdf_70 = compute_hist_cdf_mid_high(gputil_spatial_70[\"spatial_imbalance_gpu_utilization\"])\n",
    "cdf_70_100 = plot_band_70_100(gputil_spatial_70, bin_edges_70, cdf_70)\n",
    "\n",
    "cdf_0_30, cdf_31_69, cdf_70_100\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
