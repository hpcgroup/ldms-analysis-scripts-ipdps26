{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil, log2\n",
    "\n",
    "from setup_plot import setup_global, setup_local, get_colors, get_markers\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "from collections import defaultdict\n",
    "\n",
    "PARQUET_CLEAN   = \"ldms_set1.parquet\"\n",
    "SLURM_CSV       = \"slurm.csv\"\n",
    "\n",
    "UTIL_COLUMN     = \"nersc_ldms_dcgm_gpu_utilization\"\n",
    "BATCH_SIZE      = 500_000\n",
    "ROW_GROUP_SIZE  = 500_000\n",
    "\n",
    "def _norm_step_series_to_alloc(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.strip()\n",
    "    bad = (s == \"\") | s.str.lower().isin([\"nan\", \"none\"])\n",
    "    return s.mask(bad, \"alloc\").str.lower()\n",
    "\n",
    "stats = defaultdict(lambda: {\n",
    "    \"total_ts\":  0,\n",
    "    \"zero_ts\":   0,\n",
    "    \"sum_util\":  0.0,\n",
    "})\n",
    "\n",
    "dataset = ds.dataset(PARQUET_CLEAN, format=\"parquet\")\n",
    "scanner = dataset.scanner(\n",
    "    columns=[\"JobID\", \"step\", \"hostname\", \"gpu_id\", UTIL_COLUMN],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_threads=True\n",
    ")\n",
    "\n",
    "for batch in scanner.to_batches():\n",
    "    tbl  = pa.Table.from_batches([batch])\n",
    "    jid  = tbl[\"JobID\"].cast(pa.string()).to_pylist()\n",
    "    step = tbl[\"step\"].cast(pa.string()).to_pylist()\n",
    "    host = tbl[\"hostname\"].to_pylist()\n",
    "    gpu  = tbl[\"gpu_id\"].to_pylist()\n",
    "    util = tbl[UTIL_COLUMN].to_pylist()\n",
    "\n",
    "    step = [(\"alloc\" if (x is None or str(x).strip() == \"\" or str(x).lower() in (\"nan\", \"none\"))\n",
    "             else str(x).strip().lower())\n",
    "            for x in step]\n",
    "\n",
    "    for j, s, h, g, u in zip(jid, step, host, gpu, util):\n",
    "        d = stats[(j, s, h, int(g))]\n",
    "        d[\"total_ts\"] += 1\n",
    "        d[\"zero_ts\"]  += int(u == 0)\n",
    "        d[\"sum_util\"] += float(u)\n",
    "\n",
    "gpu_df = pd.DataFrame.from_records(\n",
    "    [(j, s, h, g,\n",
    "      v[\"total_ts\"], v[\"zero_ts\"], v[\"sum_util\"])\n",
    "     for (j, s, h, g), v in stats.items()],\n",
    "    columns=[\"JobID\", \"step\", \"hostname\", \"gpu_id\",\n",
    "             \"total_timestamps\", \"zero_util_timestamps\",\n",
    "             \"total_utilization\"]\n",
    ")\n",
    "del stats\n",
    "\n",
    "gpu_df[\"JobID\"] = gpu_df[\"JobID\"].astype(str)\n",
    "gpu_df[\"step\"]  = _norm_step_series_to_alloc(gpu_df[\"step\"])\n",
    "\n",
    "use_cols = [\"JobID\", \"step\", \"Start\", \"End\", \"NNodes\",\n",
    "            \"Account\", \"Partition\", \"SubmitLine\"]\n",
    "slurm = pd.read_csv(SLURM_CSV, usecols=use_cols, low_memory=False)\n",
    "\n",
    "slurm[\"JobID\"] = slurm[\"JobID\"].astype(str)\n",
    "slurm[\"step\"]  = _norm_step_series_to_alloc(slurm[\"step\"])\n",
    "\n",
    "pairs = gpu_df[[\"JobID\", \"step\"]].drop_duplicates()\n",
    "slurm = pairs.merge(slurm, on=[\"JobID\", \"step\"], how=\"left\")\n",
    "\n",
    "slurm[\"start_time\"] = (\n",
    "    pd.to_datetime(slurm[\"Start\"], errors=\"coerce\")\n",
    "      .dt.tz_localize(\"US/Pacific\")\n",
    "      .dt.tz_convert(\"UTC\")\n",
    ")\n",
    "slurm[\"end_time\"] = (\n",
    "    pd.to_datetime(slurm[\"End\"], errors=\"coerce\")\n",
    "      .dt.tz_localize(\"US/Pacific\")\n",
    "      .dt.tz_convert(\"UTC\")\n",
    ")\n",
    "\n",
    "slurm_meta = (\n",
    "    slurm.groupby([\"JobID\", \"step\"], as_index=False)\n",
    "         .agg(\n",
    "             start_time=(\"start_time\", \"min\"),\n",
    "             end_time  =(\"end_time\",   \"max\"),\n",
    "             NNodes    =(\"NNodes\",     \"max\"),\n",
    "             Account   =(\"Account\",    \"first\"),\n",
    "             Partition =(\"Partition\",  \"first\"),\n",
    "             SubmitLine=(\"SubmitLine\", \"first\")\n",
    "         )\n",
    ")\n",
    "\n",
    "gpu_df = gpu_df.merge(slurm_meta, on=[\"JobID\", \"step\"], how=\"left\", validate=\"many_to_one\")\n",
    "\n",
    "def agg_job(sub: pd.DataFrame) -> pd.Series:\n",
    "    per_gpu = (\n",
    "        sub.groupby([\"hostname\", \"gpu_id\"], as_index=False)\n",
    "           .agg(\n",
    "               total_ts=(\"total_timestamps\", \"sum\"),\n",
    "               sum_util=(\"total_utilization\", \"sum\"),\n",
    "               zero_ts =(\"zero_util_timestamps\", \"sum\"),\n",
    "           )\n",
    "    )\n",
    "\n",
    "    per_gpu = per_gpu[per_gpu[\"total_ts\"] > 0]\n",
    "\n",
    "    ngpus     = int(len(per_gpu))\n",
    "    gpu_mean  = (per_gpu[\"sum_util\"] / per_gpu[\"total_ts\"])\n",
    "    mean_util = float(gpu_mean.mean()) if ngpus > 0 else np.nan\n",
    "    zero_pct  = float(per_gpu[\"zero_ts\"].sum() / per_gpu[\"total_ts\"].sum()) if per_gpu[\"total_ts\"].sum() > 0 else np.nan\n",
    "\n",
    "    steps = (\n",
    "        sub.groupby(\"step\", as_index=False)\n",
    "           .agg(step_start=(\"start_time\", \"min\"),\n",
    "                step_end=(\"end_time\", \"max\"))\n",
    "    )\n",
    "    if not steps.empty:\n",
    "        steps[\"step_duration_sec\"] = (steps[\"step_end\"] - steps[\"step_start\"]).dt.total_seconds().clip(lower=0)\n",
    "        gpus_per_step = (\n",
    "            sub.groupby(\"step\", as_index=False)\n",
    "               .size()\n",
    "               .rename(columns={\"size\": \"gpus_in_step\"})\n",
    "        )\n",
    "        steps = steps.merge(gpus_per_step, on=\"step\", how=\"left\")\n",
    "        sum_step_duration_sec = float(steps[\"step_duration_sec\"].sum())\n",
    "        sum_step_gpu_sec      = float((steps[\"step_duration_sec\"] * steps[\"gpus_in_step\"]).sum())\n",
    "    else:\n",
    "        sum_step_duration_sec = 0.0\n",
    "        sum_step_gpu_sec      = 0.0\n",
    "\n",
    "    alloc_start = sub[\"start_time\"].min()\n",
    "    alloc_end   = sub[\"end_time\"].max()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"start_time\"             : alloc_start,\n",
    "        \"end_time\"               : alloc_end,\n",
    "        \"nnodes\"                 : int(sub[\"hostname\"].nunique()),\n",
    "        \"ngpus\"                  : ngpus,\n",
    "        \"zero_util_percentage\"   : zero_pct,\n",
    "        \"mean_utilization\"       : mean_util,\n",
    "        \"Account\"                : sub[\"Account\"].iloc[0],\n",
    "        \"Partition\"              : sub[\"Partition\"].iloc[0],\n",
    "        \"SubmitLine\"             : sub[\"SubmitLine\"].iloc[0],\n",
    "        \"step_duration\"          : sum_step_duration_sec,\n",
    "        \"step_duration_hours\"    : sum_step_duration_sec / 3600.0,\n",
    "        \"step_gpu_hours\"         : sum_step_gpu_sec / 3600.0,\n",
    "    })\n",
    "\n",
    "job_df = gpu_df.groupby(\"JobID\", sort=False).apply(agg_job).reset_index()\n",
    "\n",
    "job_df[\"duration\"]        = (job_df[\"end_time\"] - job_df[\"start_time\"]).dt.total_seconds()\n",
    "job_df[\"duration_hours\"]  = job_df[\"duration\"] / 3600.0\n",
    "job_df[\"gpu_hours\"]       = job_df[\"duration_hours\"] * job_df[\"ngpus\"]\n",
    "\n",
    "viol = job_df.loc[job_df[\"mean_utilization\"] < 1.0, \"JobID\"]\n",
    "if not viol.empty:\n",
    "    raise RuntimeError(\n",
    "        f\"{len(viol)} jobs slipped below 1% utilisation \"\n",
    "    )\n",
    "\n",
    "job_df = job_df[[\"JobID\",\"start_time\",\"end_time\",\n",
    "                 \"zero_util_percentage\",\"mean_utilization\",\n",
    "                 \"nnodes\",\"ngpus\",\n",
    "                 \"duration\",\"duration_hours\",\"gpu_hours\",\n",
    "                 \"step_duration\",\"step_duration_hours\",\"step_gpu_hours\",\n",
    "                 \"Account\",\"Partition\",\"SubmitLine\"]]\n",
    "\n",
    "gputil_all = (\n",
    "    job_df[[\"JobID\", \"ngpus\", \"duration_hours\"]]\n",
    "      .dropna(subset=[\"ngpus\", \"duration_hours\"])\n",
    "      .copy()\n",
    ")\n",
    "gputil_all[\"ngpus\"] = gputil_all[\"ngpus\"].astype(int)\n",
    "\n",
    "ng = gputil_all[\"ngpus\"].to_numpy()\n",
    "ng = ng[ng > 0]\n",
    "if ng.size < 2:\n",
    "    raise ValueError(\"Need at least two positive ngpus values for a log-x histogram.\")\n",
    "\n",
    "pmax = int(ceil(log2(ng.max())))\n",
    "top_edge = float(2 ** pmax)\n",
    "edges = 2.0 ** np.arange(0, pmax + 1)\n",
    "\n",
    "idx = np.digitize(ng, bins=edges, right=True) - 1\n",
    "idx = idx[(idx >= 0) & (idx < len(edges) - 1)]\n",
    "counts = np.bincount(idx, minlength=len(edges) - 1).astype(float)\n",
    "\n",
    "left   = edges[:-1]\n",
    "widths = np.diff(edges)\n",
    "vals   = counts\n",
    "\n",
    "if vals.size >= 2:\n",
    "    h_2nd = float(np.partition(vals, -2)[-2])\n",
    "else:\n",
    "    h_2nd = float(vals.max()) if vals.size else 1.0\n",
    "\n",
    "def nice_up(x, base):\n",
    "    return int(np.ceil(x / base) * base)\n",
    "\n",
    "step_low = max(50, nice_up(max(1.0, h_2nd / 10), 10))\n",
    "ylow_max = max(10, nice_up(1.10 * max(h_2nd, 1.0), step_low))\n",
    "\n",
    "setup_local()\n",
    "colors = get_colors()\n",
    "\n",
    "fig, (ax_top, ax_bot) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "bar_kw = dict(color=colors[2], edgecolor=\"black\", align=\"edge\")\n",
    "ax_top.bar(left, vals, width=widths, **bar_kw)\n",
    "ax_bot.bar(left, vals, width=widths, **bar_kw)\n",
    "\n",
    "ax_bot.set_ylim(0, ylow_max)\n",
    "\n",
    "ax_top.spines[\"bottom\"].set_visible(False)\n",
    "ax_bot.spines[\"top\"].set_visible(False)\n",
    "ax_top.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False,\n",
    "                   labelbottom=False, labeltop=False)\n",
    "\n",
    "d = 0.5\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color=\"k\", mec=\"k\", mew=1, clip_on=False)\n",
    "ax_top.plot([0], [0], transform=ax_top.transAxes, **kwargs)\n",
    "ax_bot.plot([0], [1], transform=ax_bot.transAxes, **kwargs)\n",
    "\n",
    "ax_top.set_yticks([62000, 64000, 66000])\n",
    "ax_top.set_ylim(60000, 66000)\n",
    "\n",
    "for ax in (ax_top, ax_bot):\n",
    "    ax.set_xscale(\"log\", base=2)\n",
    "    ax.set_xlim(1, top_edge)\n",
    "\n",
    "pow2_ticks = edges\n",
    "ax_bot.set_xticks(pow2_ticks)\n",
    "ax_bot.set_xticklabels([f\"{int(t)}\" for t in pow2_ticks],\n",
    "                       rotation=90, ha=\"right\", va=\"center\",\n",
    "                       rotation_mode=\"anchor\", fontsize=20)\n",
    "ax_bot.tick_params(axis=\"x\", pad=2)\n",
    "ax_bot.set_yticks([0, 2000, 4000, 6000])\n",
    "\n",
    "for ax in (ax_top, ax_bot):\n",
    "    ax.yaxis.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    ax.tick_params(axis=\"y\", labelsize=20)\n",
    "\n",
    "fig.supylabel(\"Number of jobs\", fontsize=21, y=0.55, x=0.07)\n",
    "ax_bot.set_xlabel(\"Job size (number of GPUs)\", fontsize=21, labelpad=10)\n",
    "plt.suptitle(\"Distribution of jobs by job size\", fontsize=23, y=0.9, x=0.58)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "gputil_all = (\n",
    "    job_df[[\"JobID\", \"ngpus\", \"duration_hours\"]]\n",
    "      .dropna(subset=[\"ngpus\", \"duration_hours\"])\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "gputil_all[\"ngpus\"] = gputil_all[\"ngpus\"].astype(int)\n",
    "gputil_all[\"duration_hours\"] = gputil_all[\"duration_hours\"].astype(float)\n",
    "\n",
    "bins = [0, 5, 9, 17, 33, 65, 129, 257, 513, 1025, 2049, 4097, 8193]\n",
    "bin_labels = [f'[{bins[i]}, {bins[i+1]-1}]' for i in range(len(bins) - 1)]\n",
    "gputil_all[\"bin\"] = np.digitize(gputil_all[\"ngpus\"], bins, right=False) - 1\n",
    "\n",
    "boxplot_data = [\n",
    "    gputil_all.loc[gputil_all[\"bin\"] == i, \"duration_hours\"].dropna()\n",
    "    for i in range(len(bins) - 1)\n",
    "]\n",
    "\n",
    "setup_local()\n",
    "colors  = get_colors()\n",
    "markers = get_markers()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "boxplot_stats = ax1.boxplot(\n",
    "    boxplot_data,\n",
    "    labels=bin_labels,\n",
    "    patch_artist=True,\n",
    "    whis=[5, 95],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    boxprops=dict(facecolor=colors[2]),\n",
    "    meanprops=dict(marker=markers[1], markerfacecolor=colors[5], markeredgecolor=colors[5]),\n",
    ")\n",
    "ax1.set_xlabel('Job size (number of GPUs)', fontsize=21)\n",
    "ax1.set_ylabel('Job duration (hours)', fontsize=21)\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax1.tick_params(axis='x', rotation=90, labelsize=20)\n",
    "ax1.tick_params(axis='y', labelsize=20)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_yticks([0.01, 0.1, 1, 10, 100])\n",
    "\n",
    "plt.title(\"Distribution of duration by job size\", fontsize=23, pad=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "gputil_all = (\n",
    "    job_df[[\"JobID\", \"ngpus\", \"mean_utilization\"]]\n",
    "      .dropna(subset=[\"ngpus\"])\n",
    "      .copy()\n",
    ")\n",
    "gputil_all[\"ngpus\"] = gputil_all[\"ngpus\"].astype(int)\n",
    "\n",
    "colors  = get_colors()\n",
    "markers = get_markers()\n",
    "\n",
    "ng = gputil_all[\"ngpus\"].to_numpy()\n",
    "ng = ng[ng > 0]\n",
    "if ng.size < 2:\n",
    "    raise ValueError(\"Need at least two positive ngpus values for a log-x histogram.\")\n",
    "\n",
    "pmax = int(ceil(log2(ng.max())))\n",
    "edges = 2.0 ** np.arange(0, pmax + 1)\n",
    "\n",
    "gputil_all = gputil_all.loc[gputil_all[\"ngpus\"] > 0].copy()\n",
    "gputil_all[\"gh_bin\"] = np.digitize(gputil_all[\"ngpus\"].to_numpy(), bins=edges, right=True) - 1\n",
    "gputil_all = gputil_all[(gputil_all[\"gh_bin\"] >= 0) & (gputil_all[\"gh_bin\"] < len(edges) - 1)].copy()\n",
    "\n",
    "nbins = len(edges) - 1\n",
    "boxplot_data = [\n",
    "    gputil_all.loc[gputil_all[\"gh_bin\"] == i, \"mean_utilization\"].dropna().to_numpy()\n",
    "    for i in range(nbins)\n",
    "]\n",
    "\n",
    "centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "bin_widths = (edges[1:] - edges[:-1]) * 0.6\n",
    "\n",
    "positions_nonempty, widths_nonempty, data_nonempty = [], [], []\n",
    "for i, arr in enumerate(boxplot_data):\n",
    "    if arr.size > 0:\n",
    "        positions_nonempty.append(centers[i])\n",
    "        widths_nonempty.append(bin_widths[i])\n",
    "        data_nonempty.append(arr)\n",
    "\n",
    "setup_local()\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.boxplot(\n",
    "    data_nonempty,\n",
    "    positions=positions_nonempty,\n",
    "    widths=widths_nonempty,\n",
    "    manage_ticks=False,\n",
    "    patch_artist=True,\n",
    "    whis=[5, 95],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    boxprops=dict(facecolor=colors[2]),\n",
    "    meanprops=dict(marker=markers[1], markerfacecolor=colors[5], markeredgecolor=colors[5]),\n",
    ")\n",
    "\n",
    "ax1.set_xscale('log', base=2)\n",
    "ax1.set_xlim(edges[0], edges[-1])\n",
    "ax1.set_xticks(edges)\n",
    "ax1.set_xticklabels([f\"{int(e)}\" for e in edges], rotation=90, ha=\"right\", va=\"center\", rotation_mode=\"anchor\")\n",
    "\n",
    "ax1.set_xlabel('Job size (number of GPUs)', fontsize=21)\n",
    "ax1.set_ylabel('Mean (of GPU_UTIL) (%)', fontsize=21)\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax1.tick_params(axis='x', rotation=90, labelsize=20)\n",
    "ax1.tick_params(axis='y', labelsize=20)\n",
    "ax1.set_ylim(0)\n",
    "ax1.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "\n",
    "plt.title(\"Distribution of GPU_UTIL by job size\", fontsize=23, pad=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
