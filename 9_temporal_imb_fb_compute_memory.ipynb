{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ec5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from setup_plot import setup_local, get_colors\n",
    "\n",
    "SET1 = \"ldms_set1.parquet\"\n",
    "SET2 = \"ldms_set2.parquet\"\n",
    "NODES_80GB_FILE = \"nodes_80gb.txt\"\n",
    "\n",
    "JOB_MEANS_ALL_OUT = \"job_means_all.parquet\"\n",
    "JOB_METRICS_OUT   = \"job_metrics.parquet\"\n",
    "JOB_METRICS_TI    = \"job_metrics_ti_all.parquet\"\n",
    "LABELS_FP64ONLY   = \"job_label_fractions_fp64only.parquet\"\n",
    "\n",
    "METRIC_COL = \"nersc_ldms_dcgm_gpu_utilization\"\n",
    "THR = 0.005\n",
    "\n",
    "DCGM_PREFIX = \"nersc_ldms_dcgm_\"\n",
    "ACTIVE_COLS = [\n",
    "    f\"{DCGM_PREFIX}fp16_active\",\n",
    "    f\"{DCGM_PREFIX}fp32_active\",\n",
    "    f\"{DCGM_PREFIX}fp64_active\",\n",
    "    f\"{DCGM_PREFIX}tensor_active\",\n",
    "    f\"{DCGM_PREFIX}dram_active\",\n",
    "]\n",
    "PEAK_FLOPS_FP64_VECTOR = 9.7e12\n",
    "HBM_40 = 1.555e12\n",
    "HBM_80 = 2.039e12\n",
    "LABEL_BATCH = 1_000_000\n",
    "\n",
    "def build_job_means_all():\n",
    "    counters = [\n",
    "        \"nersc_ldms_dcgm_fp16_active\",\n",
    "        \"nersc_ldms_dcgm_fp32_active\",\n",
    "        \"nersc_ldms_dcgm_fp64_active\",\n",
    "        \"nersc_ldms_dcgm_tensor_active\",\n",
    "    ]\n",
    "\n",
    "    def avg_expr(cols):\n",
    "        return \",\\n       \".join([f\"avg({c}) AS {c}\" for c in cols])\n",
    "\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"PRAGMA memory_limit='15GB';\")\n",
    "    con.execute(f\"PRAGMA threads={os.cpu_count() or 1};\")\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT\n",
    "            JobID,\n",
    "            {avg_expr(counters)}\n",
    "        FROM (\n",
    "            SELECT\n",
    "                JobID::VARCHAR AS JobID,\n",
    "                hostname,\n",
    "                gpu_id,\n",
    "                {avg_expr(counters)}\n",
    "            FROM parquet_scan('{SET1}')\n",
    "            GROUP BY JobID, hostname, gpu_id\n",
    "        )\n",
    "        GROUP BY JobID\n",
    "    )\n",
    "    TO '{JOB_MEANS_ALL_OUT}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\n",
    "    \"\"\")\n",
    "\n",
    "    con.close()\n",
    "\n",
    "def ti_expr_count_star(col: str, alias: str) -> str:\n",
    "    return (\n",
    "        \"CASE \"\n",
    "        f\" WHEN MAX({col}) IS NULL OR MAX({col}) <= 0 OR COUNT(*) <= 0 THEN 0.0 \"\n",
    "        \" ELSE \"\n",
    "        \"   CASE \"\n",
    "        f\"     WHEN 1.0 - SUM({col}) / (COUNT(*) * MAX({col})) < 0 THEN 0.0 \"\n",
    "        f\"     WHEN 1.0 - SUM({col}) / (COUNT(*) * MAX({col})) > 1 THEN 1.0 \"\n",
    "        f\"     ELSE 1.0 - SUM({col}) / (COUNT(*) * MAX({col})) \"\n",
    "        \"   END \"\n",
    "        f\"END AS {alias}\"\n",
    "    )\n",
    "\n",
    "def build_job_metrics_and_ti():\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"PRAGMA memory_limit='15GB';\")\n",
    "    con.execute(f\"PRAGMA threads={os.cpu_count() or 1};\")\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "      SELECT\n",
    "        JobID,\n",
    "        AVG(gpu_mean) AS mean_utilization\n",
    "      FROM (\n",
    "        SELECT\n",
    "          JobID::VARCHAR AS JobID,\n",
    "          hostname,\n",
    "          gpu_id,\n",
    "          AVG({METRIC_COL}) AS gpu_mean\n",
    "        FROM parquet_scan('{SET1}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "      )\n",
    "      GROUP BY JobID\n",
    "    )\n",
    "    TO '{JOB_METRICS_OUT}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\n",
    "    \"\"\")\n",
    "    con.close()\n",
    "\n",
    "    ti_s1 = f\"ti__{METRIC_COL}\"\n",
    "    ti_s2 = f\"ti__{METRIC_COL}_s2\"\n",
    "\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"PRAGMA memory_limit='15GB';\")\n",
    "    con.execute(f\"PRAGMA threads={os.cpu_count() or 1};\")\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "      WITH\n",
    "      s1_gpu AS (\n",
    "        SELECT\n",
    "          JobID::VARCHAR AS JobID,\n",
    "          hostname,\n",
    "          gpu_id,\n",
    "          {ti_expr_count_star(METRIC_COL, ti_s1)}\n",
    "        FROM parquet_scan('{SET1}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "      ),\n",
    "      s1_job AS (\n",
    "        SELECT JobID, MAX({ti_s1}) AS {ti_s1}\n",
    "        FROM s1_gpu\n",
    "        GROUP BY JobID\n",
    "      ),\n",
    "      s2_gpu AS (\n",
    "        SELECT\n",
    "          JobID::VARCHAR AS JobID,\n",
    "          hostname,\n",
    "          gpu_id,\n",
    "          {ti_expr_count_star(METRIC_COL, ti_s2)}\n",
    "        FROM parquet_scan('{SET2}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "      ),\n",
    "      s2_job AS (\n",
    "        SELECT JobID, MAX({ti_s2}) AS {ti_s2}\n",
    "        FROM s2_gpu\n",
    "        GROUP BY JobID\n",
    "      )\n",
    "      SELECT\n",
    "        jm.*,\n",
    "        s1_job.* EXCLUDE (JobID),\n",
    "        s2_job.* EXCLUDE (JobID)\n",
    "      FROM parquet_scan('{JOB_METRICS_OUT}') AS jm\n",
    "      LEFT JOIN s1_job USING (JobID)\n",
    "      LEFT JOIN s2_job USING (JobID)\n",
    "    )\n",
    "    TO '{JOB_METRICS_TI}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\n",
    "    \"\"\")\n",
    "\n",
    "    con.close()\n",
    "\n",
    "def load_nodes_80gb(path: str) -> set[str]:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing {p.resolve()}\")\n",
    "    nodes = set()\n",
    "    for ln in p.read_text(encoding=\"utf-8\", errors=\"replace\").splitlines():\n",
    "        ln = ln.strip()\n",
    "        if not ln or ln.startswith(\"#\"):\n",
    "            continue\n",
    "        for tok in ln.replace(\",\", \" \").split():\n",
    "            tok = tok.strip()\n",
    "            if tok and not tok.startswith(\"#\"):\n",
    "                nodes.add(tok)\n",
    "    return nodes\n",
    "\n",
    "def build_fp64only_labels():\n",
    "    nodes80 = load_nodes_80gb(NODES_80GB_FILE)\n",
    "\n",
    "    need_cols = [\"JobID\", \"hostname\", \"gpu_id\", \"ts_ns\"] + ACTIVE_COLS\n",
    "    pf = pq.ParquetFile(SET1)\n",
    "    present = set(pf.schema_arrow.names)\n",
    "    missing = [c for c in need_cols if c not in present]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns in {SET1}: {missing}\")\n",
    "\n",
    "    state = {}\n",
    "    job_time = defaultdict(lambda: {\"Compute-intensive\": 0, \"Memory-intensive\": 0, \"Other\": 0})\n",
    "    job_total = defaultdict(int)\n",
    "    job_samples = defaultdict(int)\n",
    "\n",
    "    for batch in pf.iter_batches(columns=need_cols, batch_size=LABEL_BATCH):\n",
    "        df = batch.to_pandas()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        job = df[\"JobID\"].astype(str)\n",
    "        host = df[\"hostname\"].astype(str)\n",
    "        gpu = pd.to_numeric(df[\"gpu_id\"], errors=\"coerce\")\n",
    "        ts  = pd.to_numeric(df[\"ts_ns\"], errors=\"coerce\")\n",
    "\n",
    "        fp16 = pd.to_numeric(df[f\"{DCGM_PREFIX}fp16_active\"], errors=\"coerce\")\n",
    "        fp32 = pd.to_numeric(df[f\"{DCGM_PREFIX}fp32_active\"], errors=\"coerce\")\n",
    "        fp64 = pd.to_numeric(df[f\"{DCGM_PREFIX}fp64_active\"], errors=\"coerce\")\n",
    "        tens = pd.to_numeric(df[f\"{DCGM_PREFIX}tensor_active\"], errors=\"coerce\")\n",
    "        dram = pd.to_numeric(df[f\"{DCGM_PREFIX}dram_active\"], errors=\"coerce\")\n",
    "\n",
    "        missing_any = fp16.isna() | fp32.isna() | fp64.isna() | tens.isna() | dram.isna()\n",
    "        bad_gt1 = (fp16 > 1.0) | (fp32 > 1.0) | (fp64 > 1.0) | (tens > 1.0) | (dram > 1.0)\n",
    "        all_fp_zero = (fp16.eq(0.0)) & (fp32.eq(0.0)) & (fp64.eq(0.0)) & (tens.eq(0.0))\n",
    "\n",
    "        keep = ~(bad_gt1 | all_fp_zero)\n",
    "        if not keep.any():\n",
    "            continue\n",
    "\n",
    "        job = job.loc[keep].to_numpy()\n",
    "        host = host.loc[keep].to_numpy()\n",
    "        gpu = gpu.loc[keep].to_numpy()\n",
    "        ts  = ts.loc[keep].to_numpy()\n",
    "\n",
    "        fp16 = fp16.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "        fp32 = fp32.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "        fp64 = fp64.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "        tens = tens.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "        dram = dram.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "        missing_any = missing_any.loc[keep].to_numpy(dtype=bool, copy=False)\n",
    "\n",
    "        is80 = np.fromiter((h in nodes80 for h in host), dtype=bool, count=len(host))\n",
    "        peak_hbm = np.where(is80, HBM_80, HBM_40)\n",
    "        achieved_hbm = dram * peak_hbm\n",
    "\n",
    "        ridge_fp64 = PEAK_FLOPS_FP64_VECTOR / peak_hbm\n",
    "        achieved_fp64 = fp64 * PEAK_FLOPS_FP64_VECTOR\n",
    "\n",
    "        ai_fp64 = np.full(len(job), np.nan, dtype=float)\n",
    "        np.divide(achieved_fp64, achieved_hbm, out=ai_fp64, where=(achieved_hbm > 0))\n",
    "\n",
    "        any_compute = (fp16 > 0) | (fp32 > 0) | (fp64 > 0) | (tens > 0)\n",
    "        eligible = ~missing_any\n",
    "\n",
    "        labels = np.full(len(job), \"Other\", dtype=object)\n",
    "\n",
    "        mask_inf = eligible & any_compute & (achieved_hbm <= 0)\n",
    "        labels[mask_inf] = \"Compute-intensive\"\n",
    "\n",
    "        mask_pos = eligible & (achieved_hbm > 0) & np.isfinite(ai_fp64) & np.isfinite(ridge_fp64)\n",
    "        mem = mask_pos & (ai_fp64 < ridge_fp64)\n",
    "        comp = mask_pos & ~mem\n",
    "        labels[mem] = \"Memory-intensive\"\n",
    "        labels[comp] = \"Compute-intensive\"\n",
    "\n",
    "        for j, h, g, t, lab in zip(job, host, gpu, ts, labels):\n",
    "            job_samples[j] += 1\n",
    "            if not np.isfinite(g) or not np.isfinite(t):\n",
    "                continue\n",
    "            key = (j, h, int(g))\n",
    "            t = int(t)\n",
    "\n",
    "            if key in state:\n",
    "                last_ts, last_lab = state[key]\n",
    "                dt = t - last_ts\n",
    "                if dt > 0:\n",
    "                    job_time[j][last_lab] += dt\n",
    "                    job_total[j] += dt\n",
    "\n",
    "            state[key] = (t, lab)\n",
    "\n",
    "    rows = []\n",
    "    for j, tot in job_total.items():\n",
    "        if tot <= 0:\n",
    "            continue\n",
    "        c = job_time[j][\"Compute-intensive\"]\n",
    "        m = job_time[j][\"Memory-intensive\"]\n",
    "        o = job_time[j][\"Other\"]\n",
    "        rows.append({\n",
    "            \"JobID\": j,\n",
    "            \"time_seconds\": float(tot) / 1e9,\n",
    "            \"frac_time_compute_fp64only\": c / tot,\n",
    "            \"frac_time_memory_fp64only\":  m / tot,\n",
    "            \"frac_time_other_fp64only\":   o / tot,\n",
    "            \"sample_count\": int(job_samples.get(j, 0)),\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"JobID\")\n",
    "    out.to_parquet(LABELS_FP64ONLY, index=False)\n",
    "\n",
    "def plot_ti_violins():\n",
    "    MEANS = JOB_MEANS_ALL_OUT\n",
    "    TI_GPU = JOB_METRICS_TI\n",
    "    LABELS = LABELS_FP64ONLY\n",
    "\n",
    "    # Left panel\n",
    "    cols_means = [\n",
    "        \"JobID\",\n",
    "        \"nersc_ldms_dcgm_fp16_active\",\n",
    "        \"nersc_ldms_dcgm_fp32_active\",\n",
    "        \"nersc_ldms_dcgm_fp64_active\",\n",
    "        \"nersc_ldms_dcgm_tensor_active\",\n",
    "    ]\n",
    "    dfm = pd.read_parquet(MEANS, columns=cols_means).rename(columns={\"JobID\": \"jobid\"})\n",
    "    dfm[\"fp16_active\"]   = pd.to_numeric(dfm[\"nersc_ldms_dcgm_fp16_active\"],   errors=\"coerce\") > THR\n",
    "    dfm[\"fp32_active\"]   = pd.to_numeric(dfm[\"nersc_ldms_dcgm_fp32_active\"],   errors=\"coerce\") > THR\n",
    "    dfm[\"fp64_active\"]   = pd.to_numeric(dfm[\"nersc_ldms_dcgm_fp64_active\"],   errors=\"coerce\") > THR\n",
    "    dfm[\"tensor_active\"] = pd.to_numeric(dfm[\"nersc_ldms_dcgm_tensor_active\"], errors=\"coerce\") > THR\n",
    "\n",
    "    dft_gpu = pd.read_parquet(TI_GPU, columns=[\"JobID\", f\"ti__{METRIC_COL}\"]).rename(\n",
    "        columns={\"JobID\": \"jobid\", f\"ti__{METRIC_COL}\": \"temporal_imbalance\"}\n",
    "    )\n",
    "\n",
    "    left_base = dfm.merge(dft_gpu, on=\"jobid\", how=\"inner\").dropna(subset=[\"temporal_imbalance\"])\n",
    "\n",
    "    c_fp32_only = left_base[(~left_base[\"fp16_active\"]) & ( left_base[\"fp32_active\"]) &\n",
    "                            (~left_base[\"fp64_active\"]) & (~left_base[\"tensor_active\"])].copy()\n",
    "    c_fp32_tnsr = left_base[(~left_base[\"fp16_active\"]) & ( left_base[\"fp32_active\"]) &\n",
    "                            (~left_base[\"fp64_active\"]) & ( left_base[\"tensor_active\"])].copy()\n",
    "    c_fp64_only = left_base[(~left_base[\"fp16_active\"]) & (~left_base[\"fp32_active\"]) &\n",
    "                            ( left_base[\"fp64_active\"]) & (~left_base[\"tensor_active\"])].copy()\n",
    "    c_fp64_tnsr = left_base[(~left_base[\"fp16_active\"]) & (~left_base[\"fp32_active\"]) &\n",
    "                            ( left_base[\"fp64_active\"]) & ( left_base[\"tensor_active\"])].copy()\n",
    "    c_tnsr_only = left_base[(~left_base[\"fp16_active\"]) & (~left_base[\"fp32_active\"]) &\n",
    "                            (~left_base[\"fp64_active\"]) & ( left_base[\"tensor_active\"])].copy()\n",
    "\n",
    "    for dfc, name in [\n",
    "        (c_fp32_only, \"Only FP32\"),\n",
    "        (c_fp32_tnsr, \"FP32+Tensor\"),\n",
    "        (c_fp64_only, \"Only FP64\"),\n",
    "        (c_fp64_tnsr, \"FP64+Tensor\"),\n",
    "        (c_tnsr_only, \"Only Tensor\"),\n",
    "    ]:\n",
    "        dfc[\"category\"] = name\n",
    "\n",
    "    combined_left = pd.concat([c_fp32_only, c_fp32_tnsr, c_fp64_only, c_fp64_tnsr, c_tnsr_only], ignore_index=True)\n",
    "    order_left = [\"Only FP32\", \"FP32+Tensor\", \"Only FP64\", \"FP64+Tensor\", \"Only Tensor\"]\n",
    "\n",
    "    # Right panel\n",
    "    lab = pd.read_parquet(LABELS, columns=[\"JobID\",\"frac_time_compute_fp64only\",\"frac_time_memory_fp64only\"]).copy()\n",
    "    lab[\"JobID\"] = lab[\"JobID\"].astype(str)\n",
    "    lab[\"class\"] = np.where(lab[\"frac_time_compute_fp64only\"] > lab[\"frac_time_memory_fp64only\"], \"Compute-bound\",\n",
    "                     np.where(lab[\"frac_time_memory_fp64only\"] > lab[\"frac_time_compute_fp64only\"], \"Memory-bound\", \"Other\"))\n",
    "    lab = lab[lab[\"class\"].isin([\"Compute-bound\", \"Memory-bound\"])].copy()\n",
    "\n",
    "    ti_right = pd.read_parquet(TI_GPU, columns=[\"JobID\", f\"ti__{METRIC_COL}\"]).rename(\n",
    "        columns={f\"ti__{METRIC_COL}\": \"ti_gputil\"}\n",
    "    )\n",
    "    ti_right[\"JobID\"] = ti_right[\"JobID\"].astype(str)\n",
    "\n",
    "    df_right = lab.merge(ti_right, on=\"JobID\", how=\"inner\")\n",
    "    df_right[\"ti_gputil\"] = pd.to_numeric(df_right[\"ti_gputil\"], errors=\"coerce\")\n",
    "    df_right = df_right[np.isfinite(df_right[\"ti_gputil\"])].copy()\n",
    "\n",
    "    # Plot\n",
    "    setup_local()\n",
    "    colors = get_colors()\n",
    "    fig, (ax_left, ax_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=False)\n",
    "\n",
    "    sns.violinplot(\n",
    "        ax=ax_left,\n",
    "        x=\"category\", y=\"temporal_imbalance\",\n",
    "        data=combined_left, order=order_left,\n",
    "        common_norm=True, inner=\"quartile\", cut=0, linewidth=1,\n",
    "        palette=[colors[2]]\n",
    "    )\n",
    "    for ln in ax_left.lines:\n",
    "        ln.set_color(\"white\"); ln.set_linewidth(2)\n",
    "    ax_left.set_ylabel(\"Temporal imb.\\n(of GPU_UTIL)\", fontsize=23)\n",
    "    ax_left.set_ylim(0, 1.0)\n",
    "    ax_left.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax_left.tick_params(axis=\"y\", labelsize=22)\n",
    "    ax_left.set_xlabel(\"\")\n",
    "    ax_left.tick_params(axis=\"x\", labelsize=20, rotation=90)\n",
    "    ax_left.set_title(\"Temporal imb. (of GPU_UTIL)\\nby FP pipe combinations\", fontsize=24, pad=16, x=0.45)\n",
    "    ax_left.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    sns.violinplot(\n",
    "        ax=ax_right,\n",
    "        x=\"class\", y=\"ti_gputil\", data=df_right,\n",
    "        order=[\"Compute-bound\", \"Memory-bound\"],\n",
    "        common_norm=True, inner=\"quartile\", cut=0, linewidth=1,\n",
    "        palette=[colors[4], colors[5]]\n",
    "    )\n",
    "    for ln in ax_right.lines:\n",
    "        ln.set_color(\"white\"); ln.set_linewidth(2)\n",
    "    ax_right.tick_params(axis=\"y\", labelsize=22)\n",
    "    ax_right.tick_params(axis=\"x\", labelsize=22)\n",
    "    ax_right.set_ylim(0, 1.0)\n",
    "    ax_right.set_ylabel(\"Temporal imb.\\n(of GPU_UTIL)\", fontsize=23)\n",
    "    ax_right.set_xlabel(\"\")\n",
    "    ax_right.set_title(\"Temporal imb. (of GPU_UTIL)\\n(Compute- vs Memory-bound)\", fontsize=24, pad=16, x=0.50)\n",
    "    ax_right.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    ax_right.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "build_job_means_all()\n",
    "build_job_metrics_and_ti()\n",
    "build_fp64only_labels()\n",
    "plot_ti_violins()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
