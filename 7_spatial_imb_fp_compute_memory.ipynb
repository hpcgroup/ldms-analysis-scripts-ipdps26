{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import duckdb\n",
    "from setup_plot import setup_local, get_colors\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.compute as pc\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "SET1_PARQUET = \"ldms_set1.parquet\"\n",
    "NODES_80GB_FILE = \"nodes_80gb.txt\" \n",
    "\n",
    "JOB_MEANS_ALL_OUT = \"job_means_all.parquet\"\n",
    "SI_GPU_PATH       = \"si_jobs_set1_ldms_parts/nersc_ldms_dcgm_gpu_utilization.parquet\"\n",
    "LABELS_FP64ONLY   = \"job_label_fractions_fp64only.parquet\"\n",
    "\n",
    "COUNTERS = [\n",
    "    \"nersc_ldms_dcgm_fp16_active\",\n",
    "    \"nersc_ldms_dcgm_fp32_active\",\n",
    "    \"nersc_ldms_dcgm_fp64_active\",\n",
    "    \"nersc_ldms_dcgm_tensor_active\",\n",
    "]\n",
    "\n",
    "def avg_expr(cols):\n",
    "    return \",\\n       \".join([f\"avg({c}) AS {c}\" for c in cols])\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"PRAGMA memory_limit='15GB';\")\n",
    "con.execute(f\"PRAGMA threads={os.cpu_count()};\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "COPY (\n",
    "    SELECT\n",
    "        JobID,\n",
    "        {avg_expr(COUNTERS)}\n",
    "    FROM (\n",
    "        SELECT\n",
    "            JobID::VARCHAR AS JobID,\n",
    "            hostname,\n",
    "            gpu_id,\n",
    "            {avg_expr(COUNTERS)}\n",
    "        FROM parquet_scan('{SET1_PARQUET}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "    )\n",
    "    GROUP BY JobID\n",
    ")\n",
    "TO '{JOB_MEANS_ALL_OUT}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\n",
    "\"\"\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "\n",
    "METRIC = \"nersc_ldms_dcgm_gpu_utilization\"\n",
    "\n",
    "SAMPLE_SEC = 10\n",
    "WINDOW_SEC = 60\n",
    "assert WINDOW_SEC % SAMPLE_SEC == 0\n",
    "TICKS_PER_WINDOW = WINDOW_SEC // SAMPLE_SEC\n",
    "SNS = SAMPLE_SEC * 1_000_000_000\n",
    "\n",
    "BATCH_SIZE = 500_000\n",
    "\n",
    "OUT_DIR_WIN = Path(\"si_windows_set1_ldms_parts\")\n",
    "OUT_DIR_JOB = Path(\"si_jobs_set1_ldms_parts\")\n",
    "OUT_DIR_WIN.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR_JOB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "@dataclass\n",
    "class JobAnchor:\n",
    "    ts0: int\n",
    "    g_ldms: int\n",
    "\n",
    "def build_job_anchors(parquet_path: str) -> dict:\n",
    "    ds_in = ds.dataset(parquet_path, format=\"parquet\")\n",
    "    scanner = ds_in.scanner(\n",
    "        columns=[\"JobID\", \"hostname\", \"gpu_id\", \"ts_ns\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        use_threads=True\n",
    "    )\n",
    "\n",
    "    ts0_map = {}\n",
    "    gpu_sets = defaultdict(set)\n",
    "\n",
    "    for rb in scanner.to_batches():\n",
    "        jid  = pc.cast(rb[\"JobID\"], pa.string()).to_pylist()\n",
    "        host = rb[\"hostname\"].to_pylist()\n",
    "        gid  = pc.cast(rb[\"gpu_id\"], pa.int64()).to_numpy()\n",
    "        ts   = pc.cast(rb[\"ts_ns\"], pa.int64()).to_numpy()\n",
    "\n",
    "        for j, h, g, t in zip(jid, host, gid, ts):\n",
    "            if j is None:\n",
    "                continue\n",
    "            prev = ts0_map.get(j)\n",
    "            if prev is None or t < prev:\n",
    "                ts0_map[j] = int(t)\n",
    "            gpu_sets[j].add((h, int(g)))\n",
    "\n",
    "    anchors = {}\n",
    "    for j, t0 in ts0_map.items():\n",
    "        gobs = len(gpu_sets[j])\n",
    "        if gobs > 1: \n",
    "            anchors[j] = JobAnchor(ts0=int(t0), g_ldms=gobs)\n",
    "\n",
    "    return anchors\n",
    "\n",
    "def compute_gpuutil_si(parquet_path: str, anchors: dict) -> None:\n",
    "    ds_in = ds.dataset(parquet_path, format=\"parquet\")\n",
    "    cols = [\"JobID\", \"hostname\", \"gpu_id\", \"ts_ns\", METRIC]\n",
    "    scanner = ds_in.scanner(columns=cols, batch_size=BATCH_SIZE, use_threads=True)\n",
    "\n",
    "    tc_per_gpu = defaultdict(float)\n",
    "    seen_jobs = set()\n",
    "\n",
    "    for rb in scanner.to_batches():\n",
    "        jid  = pc.cast(rb[\"JobID\"], pa.string()).to_pylist()\n",
    "        host = rb[\"hostname\"].to_pylist()\n",
    "        gid  = pc.cast(rb[\"gpu_id\"], pa.int64()).to_numpy()\n",
    "        ts   = pc.cast(rb[\"ts_ns\"], pa.int64()).to_numpy()\n",
    "        val  = pc.cast(rb[METRIC], pa.float64()).to_numpy(zero_copy_only=False)\n",
    "\n",
    "        for j, h, g, t, v in zip(jid, host, gid, ts, val):\n",
    "            if j is None or np.isnan(v):\n",
    "                continue\n",
    "            a = anchors.get(j)\n",
    "            if a is None:\n",
    "                continue\n",
    "\n",
    "            dt = t - a.ts0\n",
    "            if dt < 0:\n",
    "                continue\n",
    "\n",
    "            k = int((dt + (SNS // 2)) // SNS)\n",
    "            widx = k // TICKS_PER_WINDOW\n",
    "\n",
    "            tc_per_gpu[(j, widx, (h, int(g)))] += float(v)\n",
    "            seen_jobs.add(j)\n",
    "\n",
    "    if not tc_per_gpu:\n",
    "        raise RuntimeError(\"No present windows for GPU_UTIL.\")\n",
    "\n",
    "    sum_tc_by_win = defaultdict(float)\n",
    "    max_tc_by_win = defaultdict(float)\n",
    "\n",
    "    for (j, widx, _gpu_key), tc in tc_per_gpu.items():\n",
    "        key = (j, widx)\n",
    "        sum_tc_by_win[key] += tc\n",
    "        if tc > max_tc_by_win[key]:\n",
    "            max_tc_by_win[key] = tc\n",
    "\n",
    "    win_rows = []\n",
    "    for (j, widx), sum_tc in sum_tc_by_win.items():\n",
    "        max_tc = max_tc_by_win[(j, widx)]\n",
    "        g_ldms = anchors[j].g_ldms\n",
    "\n",
    "        if max_tc <= 0 or g_ldms <= 0:\n",
    "            si_w = 0.0\n",
    "        else:\n",
    "            si_w = 1.0 - (sum_tc / (max_tc * g_ldms))\n",
    "            if si_w < 0.0: si_w = 0.0\n",
    "            if si_w > 1.0: si_w = 1.0\n",
    "\n",
    "        win_rows.append((j, METRIC, widx, float(sum_tc), float(max_tc), int(g_ldms), float(si_w)))\n",
    "\n",
    "    win_df = pd.DataFrame(\n",
    "        win_rows,\n",
    "        columns=[\"JobID\", \"metric\", \"window_idx\", \"sum_TC\", \"max_TC\", \"g_ldms\", \"SI_jw\"]\n",
    "    )\n",
    "    pq.write_table(pa.Table.from_pandas(win_df, preserve_index=False),\n",
    "                   (OUT_DIR_WIN / f\"{METRIC}.parquet\").as_posix(),\n",
    "                   compression=\"snappy\")\n",
    "\n",
    "    w_present_by_job = defaultdict(int)\n",
    "    si_sum_by_job = defaultdict(float)\n",
    "    active_any_by_job = defaultdict(bool)\n",
    "\n",
    "    for _, r in win_df.iterrows():\n",
    "        j = r[\"JobID\"]\n",
    "        w_present_by_job[j] += 1\n",
    "        si_sum_by_job[j] += r[\"SI_jw\"]\n",
    "        if r[\"max_TC\"] > 0:\n",
    "            active_any_by_job[j] = True\n",
    "\n",
    "    job_rows = []\n",
    "    for j in seen_jobs:\n",
    "        w_present = w_present_by_job.get(j, 0)\n",
    "        if w_present == 0:\n",
    "            continue\n",
    "        if not active_any_by_job.get(j, False):\n",
    "            continue\n",
    "        si_mean = si_sum_by_job[j] / float(w_present)\n",
    "        job_rows.append((j, METRIC, int(anchors[j].g_ldms), int(w_present), float(si_mean)))\n",
    "\n",
    "    if not job_rows:\n",
    "        raise RuntimeError(\"No jobs passed SI filters.\")\n",
    "\n",
    "    job_df = pd.DataFrame(job_rows, columns=[\"JobID\", \"metric\", \"g_ldms\", \"w_present\", \"SI_mean\"])\n",
    "    pq.write_table(pa.Table.from_pandas(job_df, preserve_index=False),\n",
    "                   (OUT_DIR_JOB / f\"{METRIC}.parquet\").as_posix(),\n",
    "                   compression=\"snappy\")\n",
    "\n",
    "anchors = build_job_anchors(SET1_PARQUET)\n",
    "if not anchors:\n",
    "    raise RuntimeError(\"No multi-GPU jobs found in set1.\")\n",
    "compute_gpuutil_si(SET1_PARQUET, anchors)\n",
    "\n",
    "\n",
    "DCGM_PREFIX = \"nersc_ldms_dcgm_\"\n",
    "ACTIVE_COLS = [\n",
    "    f\"{DCGM_PREFIX}fp16_active\",\n",
    "    f\"{DCGM_PREFIX}fp32_active\",\n",
    "    f\"{DCGM_PREFIX}fp64_active\",\n",
    "    f\"{DCGM_PREFIX}tensor_active\",\n",
    "    f\"{DCGM_PREFIX}dram_active\",\n",
    "]\n",
    "\n",
    "PEAK_FLOPS_FP64_VECTOR = 9.7e12\n",
    "HBM_40 = 1.555e12\n",
    "HBM_80 = 2.039e12\n",
    "\n",
    "LABEL_BATCH = 1_000_000\n",
    "\n",
    "def load_nodes_80gb(path: str) -> set[str]:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing {p.resolve()}\")\n",
    "    nodes = set()\n",
    "    for ln in p.read_text(encoding=\"utf-8\", errors=\"replace\").splitlines():\n",
    "        ln = ln.strip()\n",
    "        if not ln or ln.startswith(\"#\"):\n",
    "            continue\n",
    "        for tok in ln.replace(\",\", \" \").split():\n",
    "            tok = tok.strip()\n",
    "            if tok and not tok.startswith(\"#\"):\n",
    "                nodes.add(tok)\n",
    "    return nodes\n",
    "\n",
    "nodes80 = load_nodes_80gb(NODES_80GB_FILE)\n",
    "\n",
    "need_cols = [\"JobID\", \"hostname\", \"gpu_id\", \"ts_ns\"] + ACTIVE_COLS\n",
    "pf = pq.ParquetFile(SET1_PARQUET)\n",
    "present = set(pf.schema_arrow.names)\n",
    "missing = [c for c in need_cols if c not in present]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns in {SET1_PARQUET}: {missing}\")\n",
    "\n",
    "state = {} \n",
    "job_time = defaultdict(lambda: {\"Compute-intensive\": 0, \"Memory-intensive\": 0, \"Other\": 0})\n",
    "job_total = defaultdict(int)\n",
    "job_samples = defaultdict(int)\n",
    "\n",
    "for batch in pf.iter_batches(columns=need_cols, batch_size=LABEL_BATCH):\n",
    "    df = batch.to_pandas()\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    job = df[\"JobID\"].astype(str)\n",
    "    host = df[\"hostname\"].astype(str)\n",
    "    gpu = pd.to_numeric(df[\"gpu_id\"], errors=\"coerce\")\n",
    "    ts  = pd.to_numeric(df[\"ts_ns\"], errors=\"coerce\")\n",
    "\n",
    "    fp16 = pd.to_numeric(df[f\"{DCGM_PREFIX}fp16_active\"], errors=\"coerce\")\n",
    "    fp32 = pd.to_numeric(df[f\"{DCGM_PREFIX}fp32_active\"], errors=\"coerce\")\n",
    "    fp64 = pd.to_numeric(df[f\"{DCGM_PREFIX}fp64_active\"], errors=\"coerce\")\n",
    "    tens = pd.to_numeric(df[f\"{DCGM_PREFIX}tensor_active\"], errors=\"coerce\")\n",
    "    dram = pd.to_numeric(df[f\"{DCGM_PREFIX}dram_active\"], errors=\"coerce\")\n",
    "\n",
    "    missing_any = fp16.isna() | fp32.isna() | fp64.isna() | tens.isna() | dram.isna()\n",
    "    bad_gt1 = (fp16 > 1.0) | (fp32 > 1.0) | (fp64 > 1.0) | (tens > 1.0) | (dram > 1.0)\n",
    "    all_fp_zero = (fp16.eq(0.0)) & (fp32.eq(0.0)) & (fp64.eq(0.0)) & (tens.eq(0.0))\n",
    "\n",
    "    keep = ~(bad_gt1 | all_fp_zero)\n",
    "    if not keep.any():\n",
    "        continue\n",
    "\n",
    "    job = job.loc[keep].to_numpy()\n",
    "    host = host.loc[keep].to_numpy()\n",
    "    gpu = gpu.loc[keep].to_numpy()\n",
    "    ts  = ts.loc[keep].to_numpy()\n",
    "\n",
    "    fp16 = fp16.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "    fp32 = fp32.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "    fp64 = fp64.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "    tens = tens.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "    dram = dram.loc[keep].to_numpy(dtype=float, copy=False)\n",
    "    missing_any = missing_any.loc[keep].to_numpy(dtype=bool, copy=False)\n",
    "\n",
    "    is80 = np.fromiter((h in nodes80 for h in host), dtype=bool, count=len(host))\n",
    "    peak_hbm = np.where(is80, HBM_80, HBM_40)\n",
    "    achieved_hbm = dram * peak_hbm\n",
    "\n",
    "    ridge_fp64 = PEAK_FLOPS_FP64_VECTOR / peak_hbm\n",
    "    achieved_fp64 = fp64 * PEAK_FLOPS_FP64_VECTOR\n",
    "\n",
    "    ai_fp64 = np.full(len(job), np.nan, dtype=float)\n",
    "    np.divide(achieved_fp64, achieved_hbm, out=ai_fp64, where=(achieved_hbm > 0))\n",
    "\n",
    "    any_compute = (fp16 > 0) | (fp32 > 0) | (fp64 > 0) | (tens > 0)\n",
    "    eligible = ~missing_any\n",
    "\n",
    "    labels = np.full(len(job), \"Other\", dtype=object)\n",
    "\n",
    "    mask_inf = eligible & any_compute & (achieved_hbm <= 0)\n",
    "    labels[mask_inf] = \"Compute-intensive\"\n",
    "\n",
    "    mask_pos = eligible & (achieved_hbm > 0) & np.isfinite(ai_fp64) & np.isfinite(ridge_fp64)\n",
    "    mem = mask_pos & (ai_fp64 < ridge_fp64)\n",
    "    comp = mask_pos & ~mem\n",
    "    labels[mem] = \"Memory-intensive\"\n",
    "    labels[comp] = \"Compute-intensive\"\n",
    "\n",
    "    for j, h, g, t, lab in zip(job, host, gpu, ts, labels):\n",
    "        job_samples[j] += 1\n",
    "        if not np.isfinite(g) or not np.isfinite(t):\n",
    "            continue\n",
    "        key = (j, h, int(g))\n",
    "        t = int(t)\n",
    "\n",
    "        if key in state:\n",
    "            last_ts, last_lab = state[key]\n",
    "            dt = t - last_ts\n",
    "            if dt > 0:\n",
    "                job_time[j][last_lab] += dt\n",
    "                job_total[j] += dt\n",
    "\n",
    "        state[key] = (t, lab)\n",
    "\n",
    "rows = []\n",
    "for j, tot in job_total.items():\n",
    "    if tot <= 0:\n",
    "        continue\n",
    "    c = job_time[j][\"Compute-intensive\"]\n",
    "    m = job_time[j][\"Memory-intensive\"]\n",
    "    o = job_time[j][\"Other\"]\n",
    "    rows.append({\n",
    "        \"JobID\": j,\n",
    "        \"time_seconds\": float(tot) / 1e9,\n",
    "        \"frac_time_compute_fp64only\": c / tot,\n",
    "        \"frac_time_memory_fp64only\":  m / tot,\n",
    "        \"frac_time_other_fp64only\":   o / tot,\n",
    "        \"sample_count\": int(job_samples.get(j, 0)),\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(rows).sort_values(\"JobID\")\n",
    "out.to_parquet(LABELS_FP64ONLY, index=False)\n",
    "\n",
    "MEANS = \"job_means_all.parquet\"\n",
    "SI_GPU = \"si_jobs_set1_ldms_parts/nersc_ldms_dcgm_gpu_utilization.parquet\"\n",
    "LABELS_FP64ONLY = \"job_label_fractions_fp64only.parquet\"\n",
    "\n",
    "THR = 0.005\n",
    "\n",
    "cols_means = [\n",
    "    \"JobID\",\n",
    "    \"nersc_ldms_dcgm_fp16_active\",\n",
    "    \"nersc_ldms_dcgm_fp32_active\",\n",
    "    \"nersc_ldms_dcgm_fp64_active\",\n",
    "    \"nersc_ldms_dcgm_tensor_active\",\n",
    "]\n",
    "dfm = pd.read_parquet(MEANS, columns=cols_means).rename(columns={\"JobID\": \"jobid\"})\n",
    "dfm[\"fp16_active\"]   = pd.to_numeric(dfm[\"nersc_ldms_dcgm_fp16_active\"],   errors=\"coerce\") > THR\n",
    "dfm[\"fp32_active\"]   = pd.to_numeric(dfm[\"nersc_ldms_dcgm_fp32_active\"],   errors=\"coerce\") > THR\n",
    "dfm[\"fp64_active\"]   = pd.to_numeric(dfm[\"nersc_ldms_dcgm_fp64_active\"],   errors=\"coerce\") > THR\n",
    "dfm[\"tensor_active\"] = pd.to_numeric(dfm[\"nersc_ldms_dcgm_tensor_active\"], errors=\"coerce\") > THR\n",
    "\n",
    "df_si = pd.read_parquet(SI_GPU, columns=[\"JobID\",\"SI_mean\"]).rename(columns={\"JobID\":\"jobid\",\"SI_mean\":\"spatial_imbalance\"})\n",
    "left_base = dfm.merge(df_si, on=\"jobid\", how=\"inner\")\n",
    "left_base = left_base.dropna(subset=[\"spatial_imbalance\"])\n",
    "\n",
    "c_fp32_only = left_base[(~left_base[\"fp16_active\"]) & ( left_base[\"fp32_active\"]) & (~left_base[\"fp64_active\"]) & (~left_base[\"tensor_active\"])].copy()\n",
    "c_fp32_tnsr = left_base[(~left_base[\"fp16_active\"]) & ( left_base[\"fp32_active\"]) & (~left_base[\"fp64_active\"]) & ( left_base[\"tensor_active\"])].copy()\n",
    "c_fp64_only = left_base[(~left_base[\"fp16_active\"]) & (~left_base[\"fp32_active\"]) & ( left_base[\"fp64_active\"]) & (~left_base[\"tensor_active\"])].copy()\n",
    "c_fp64_tnsr = left_base[(~left_base[\"fp16_active\"]) & (~left_base[\"fp32_active\"]) & ( left_base[\"fp64_active\"]) & ( left_base[\"tensor_active\"])].copy()\n",
    "c_tnsr_only = left_base[(~left_base[\"fp16_active\"]) & (~left_base[\"fp32_active\"]) & (~left_base[\"fp64_active\"]) & ( left_base[\"tensor_active\"])].copy()\n",
    "\n",
    "for dfc, name in [\n",
    "    (c_fp32_only, \"Only FP32\"),\n",
    "    (c_fp32_tnsr, \"FP32+Tensor\"),\n",
    "    (c_fp64_only, \"Only FP64\"),\n",
    "    (c_fp64_tnsr, \"FP64+Tensor\"),\n",
    "    (c_tnsr_only, \"Only Tensor\"),\n",
    "]:\n",
    "    dfc[\"category\"] = name\n",
    "\n",
    "combined_left = pd.concat([c_fp32_only, c_fp32_tnsr, c_fp64_only, c_fp64_tnsr, c_tnsr_only], ignore_index=True)\n",
    "order_left = [\"Only FP32\",\"FP32+Tensor\",\"Only FP64\",\"FP64+Tensor\",\"Only Tensor\"]\n",
    "\n",
    "lab = pd.read_parquet(LABELS_FP64ONLY, columns=[\"JobID\",\"frac_time_compute_fp64only\",\"frac_time_memory_fp64only\"]) \\\n",
    "        .rename(columns={\"JobID\":\"JobID\"})\n",
    "lab[\"class\"] = np.where(lab[\"frac_time_compute_fp64only\"] > lab[\"frac_time_memory_fp64only\"], \"Compute-bound\",\n",
    "                 np.where(lab[\"frac_time_memory_fp64only\"] > lab[\"frac_time_compute_fp64only\"], \"Memory-bound\", \"Other\"))\n",
    "lab = lab[lab[\"class\"].isin([\"Compute-bound\",\"Memory-bound\"])].copy()\n",
    "\n",
    "df_si_right = pd.read_parquet(SI_GPU, columns=[\"JobID\",\"SI_mean\"]).rename(columns={\"JobID\":\"JobID\",\"SI_mean\":\"si_gpuutil\"})\n",
    "df_right = lab.merge(df_si_right, on=\"JobID\", how=\"inner\")\n",
    "df_right[\"si_gpuutil\"] = pd.to_numeric(df_right[\"si_gpuutil\"], errors=\"coerce\")\n",
    "df_right = df_right[np.isfinite(df_right[\"si_gpuutil\"])].copy()\n",
    "\n",
    "setup_local()\n",
    "colors = get_colors()\n",
    "\n",
    "fig, (ax_left, ax_right) = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=False)\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=ax_left,\n",
    "    x=\"category\", y=\"spatial_imbalance\",\n",
    "    data=combined_left, order=order_left, common_norm=True,\n",
    "    density_norm=\"area\",\n",
    "    inner=\"quartile\", cut=0, linewidth=1, palette=[colors[2]]\n",
    ")\n",
    "for ln in ax_left.lines:\n",
    "    ln.set_color(\"white\"); ln.set_linewidth(2)\n",
    "ax_left.set_ylabel(\"Spatial imb.\\n(of GPU_UTIL)\", fontsize=23)\n",
    "ax_left.set_ylim(0, 1.0)\n",
    "ax_left.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax_left.tick_params(axis='y', labelsize=22)\n",
    "ax_left.set_xlabel(\"\")\n",
    "ax_left.tick_params(axis='x', labelsize=20, rotation=90)\n",
    "ax_left.set_title(\"Spatial imb. (of GPU_UTIL)\\nby FP pipe combinations\", fontsize=24, pad=16, x=0.45)\n",
    "ax_left.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=ax_right,\n",
    "    x=\"class\", y=\"si_gpuutil\", data=df_right,\n",
    "    order=[\"Compute-bound\",\"Memory-bound\"],\n",
    "    common_norm=True, inner=\"quartile\", cut=0, linewidth=1,\n",
    "    palette=[colors[4], colors[5]]\n",
    ")\n",
    "for ln in ax_right.lines:\n",
    "    ln.set_color(\"white\"); ln.set_linewidth(2)\n",
    "ax_right.tick_params(axis='y', labelsize=22)\n",
    "ax_right.tick_params(axis='x', labelsize=22)\n",
    "ax_right.set_ylim(0, 1.0)\n",
    "ax_right.set_ylabel(\"Spatial imb.\\n(of GPU_UTIL)\", fontsize=23)\n",
    "ax_right.set_xlabel(\"\")\n",
    "ax_right.set_title(\"Spatial imb. (of GPU_UTIL)\\n(Compute- vs Memory-bound)\", fontsize=24, pad=16, x=0.50)\n",
    "ax_right.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "ax_right.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
