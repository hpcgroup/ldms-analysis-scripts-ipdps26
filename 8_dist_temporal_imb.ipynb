{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e86a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from setup_plot import setup_local, get_colors, get_markers\n",
    "\n",
    "\n",
    "SET1 = \"ldms_set1.parquet\"\n",
    "SET2 = \"ldms_set2.parquet\"\n",
    "\n",
    "METRIC_COL = \"nersc_ldms_dcgm_gpu_utilization\"\n",
    "\n",
    "JOB_METRICS_OUT = \"job_metrics.parquet\"\n",
    "OUT_JOB_ALL     = \"job_metrics_ti_all.parquet\" \n",
    "\n",
    "def ti_expr_count_star(col: str, alias: str) -> str:\n",
    "    return (\n",
    "        \"CASE \"\n",
    "        f\" WHEN MAX({col}) IS NULL OR MAX({col}) <= 0 OR COUNT(*) <= 0 THEN 0.0 \"\n",
    "        \" ELSE \"\n",
    "        \"   CASE \"\n",
    "        f\"     WHEN 1.0 - SUM({col}) / (COUNT(*) * MAX({col})) < 0 THEN 0.0 \"\n",
    "        f\"     WHEN 1.0 - SUM({col}) / (COUNT(*) * MAX({col})) > 1 THEN 1.0 \"\n",
    "        f\"     ELSE 1.0 - SUM({col}) / (COUNT(*) * MAX({col})) \"\n",
    "        \"   END \"\n",
    "        f\"END AS {alias}\"\n",
    "    )\n",
    "\n",
    "def build_job_metrics_mean_utilization():\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"PRAGMA memory_limit='15GB';\")\n",
    "    con.execute(f\"PRAGMA threads={os.cpu_count() or 1};\")\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "      SELECT\n",
    "        JobID,\n",
    "        AVG(gpu_mean) AS mean_utilization\n",
    "      FROM (\n",
    "        SELECT\n",
    "          JobID::VARCHAR AS JobID,\n",
    "          hostname,\n",
    "          gpu_id,\n",
    "          AVG({METRIC_COL}) AS gpu_mean\n",
    "        FROM parquet_scan('{SET1}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "      )\n",
    "      GROUP BY JobID\n",
    "    )\n",
    "    TO '{JOB_METRICS_OUT}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\n",
    "    \"\"\")\n",
    "\n",
    "    con.close()\n",
    "\n",
    "def build_job_metrics_ti_all_gpuutil():\n",
    "    con = duckdb.connect()\n",
    "    con.execute(\"PRAGMA memory_limit='15GB';\")\n",
    "    con.execute(f\"PRAGMA threads={os.cpu_count() or 1};\")\n",
    "\n",
    "    ti_s1 = f\"ti__{METRIC_COL}\"\n",
    "    ti_s2 = f\"ti__{METRIC_COL}_s2\"\n",
    "\n",
    "    con.execute(f\"\"\"\n",
    "    COPY (\n",
    "      WITH\n",
    "      s1_gpu AS (\n",
    "        SELECT\n",
    "          JobID::VARCHAR AS JobID,\n",
    "          hostname,\n",
    "          gpu_id,\n",
    "          {ti_expr_count_star(METRIC_COL, ti_s1)}\n",
    "        FROM parquet_scan('{SET1}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "      ),\n",
    "      s1_job AS (\n",
    "        SELECT JobID, MAX({ti_s1}) AS {ti_s1}\n",
    "        FROM s1_gpu\n",
    "        GROUP BY JobID\n",
    "      ),\n",
    "      s2_gpu AS (\n",
    "        SELECT\n",
    "          JobID::VARCHAR AS JobID,\n",
    "          hostname,\n",
    "          gpu_id,\n",
    "          {ti_expr_count_star(METRIC_COL, ti_s2)}\n",
    "        FROM parquet_scan('{SET2}')\n",
    "        GROUP BY JobID, hostname, gpu_id\n",
    "      ),\n",
    "      s2_job AS (\n",
    "        SELECT JobID, MAX({ti_s2}) AS {ti_s2}\n",
    "        FROM s2_gpu\n",
    "        GROUP BY JobID\n",
    "      )\n",
    "      SELECT\n",
    "        jm.*,\n",
    "        s1_job.* EXCLUDE (JobID),\n",
    "        s2_job.* EXCLUDE (JobID)\n",
    "      FROM parquet_scan('{JOB_METRICS_OUT}') AS jm\n",
    "      LEFT JOIN s1_job USING (JobID)\n",
    "      LEFT JOIN s2_job USING (JobID)\n",
    "    )\n",
    "    TO '{OUT_JOB_ALL}' (FORMAT PARQUET, COMPRESSION 'SNAPPY');\n",
    "    \"\"\")\n",
    "\n",
    "    con.close()\n",
    "\n",
    "def pick_ti_col(ti_file: str) -> str:\n",
    "    pf = pq.ParquetFile(ti_file)\n",
    "    names = pf.schema_arrow.names\n",
    "    base = f\"ti__{METRIC_COL}\"\n",
    "    s2   = f\"ti__{METRIC_COL}_s2\"\n",
    "    if base in names:\n",
    "        return base\n",
    "    if s2 in names:\n",
    "        return s2\n",
    "    return next(c for c in names if c.startswith(\"ti__\") and \"gpu_utilization\" in c)\n",
    "\n",
    "def plot_one_band(df: pd.DataFrame, mask: pd.Series, xlabel: str, legend_label: str):\n",
    "    sub = df.loc[mask].copy()\n",
    "\n",
    "    hist_values, bin_edges = np.histogram(sub[\"temporal_imbalance\"], bins=20, density=False)\n",
    "    cumulative_hist = np.cumsum(hist_values)\n",
    "    cdf = (cumulative_hist / cumulative_hist[-1] * 100.0) if cumulative_hist[-1] > 0 else cumulative_hist.astype(float)\n",
    "\n",
    "    setup_local()\n",
    "    colors, markers = get_colors(), get_markers()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(sub[\"temporal_imbalance\"], bins=20, range=(0,1),\n",
    "             color=colors[2], edgecolor=\"black\", alpha=0.7, label=\"Number of Jobs\")\n",
    "    ax1.set_xlabel(xlabel, fontsize=21)\n",
    "    ax1.set_ylabel(\"Number of jobs\", fontsize=21)\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax1.set_yticks([0, 2000, 4000, 6000, 8000, 10000])\n",
    "    ax1.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=20)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot((bin_edges[:-1] + bin_edges[1:]) / 2, cdf,\n",
    "             color=colors[0], marker=markers[2],\n",
    "             label=legend_label, linewidth=2, clip_on=False)\n",
    "    ax2.set_ylabel(\"Cumulative percentage (%)\", fontsize=21)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=20)\n",
    "    ax2.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    ax2.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "\n",
    "    plt.legend(loc=\"upper left\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return cdf\n",
    "\n",
    "def plot_three_bands():\n",
    "    ti_col = pick_ti_col(OUT_JOB_ALL)\n",
    "\n",
    "    df = pd.read_parquet(OUT_JOB_ALL, columns=[\"JobID\", \"mean_utilization\", ti_col]).rename(columns={ti_col: \"temporal_imbalance\"})\n",
    "    df[\"mean_utilization\"] = pd.to_numeric(df[\"mean_utilization\"], errors=\"coerce\")\n",
    "    df[\"temporal_imbalance\"] = pd.to_numeric(df[\"temporal_imbalance\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"mean_utilization\", \"temporal_imbalance\"]).copy()\n",
    "\n",
    "    cdf_0_30 = plot_one_band(\n",
    "        df,\n",
    "        (df[\"mean_utilization\"] >= 0) & (df[\"mean_utilization\"] <= 30),\n",
    "        \"Temporal imb. (of GPU_UTIL)\\n(mean of GPU_UTIL: 0%–30%)\",\n",
    "        \"CDF (number of jobs)\",\n",
    "    )\n",
    "    cdf_31_69 = plot_one_band(\n",
    "        df,\n",
    "        (df[\"mean_utilization\"] > 30) & (df[\"mean_utilization\"] < 70),\n",
    "        \"Temporal imb. (of GPU_UTIL)\\n(mean of GPU_UTIL: 31%–69%)\",\n",
    "        \"CDF (number of Jobs)\",\n",
    "    )\n",
    "    cdf_70_100 = plot_one_band(\n",
    "        df,\n",
    "        (df[\"mean_utilization\"] >= 70) & (df[\"mean_utilization\"] <= 100),\n",
    "        \"Temporal imb. (of GPU_UTIL)\\n(mean of GPU_UTIL: 70%–100%)\",\n",
    "        \"CDF (number of jobs)\",\n",
    "    )\n",
    "    return cdf_0_30, cdf_31_69, cdf_70_100\n",
    "\n",
    "build_job_metrics_mean_utilization()\n",
    "build_job_metrics_ti_all_gpuutil()\n",
    "cdf_0_30, cdf_31_69, cdf_70_100 = plot_three_bands()\n",
    "cdf_0_30, cdf_31_69, cdf_70_100\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
